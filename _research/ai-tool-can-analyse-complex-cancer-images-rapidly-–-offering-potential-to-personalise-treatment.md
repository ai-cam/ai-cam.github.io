---
layout: research-single
title: AI tool can analyse complex cancer images rapidly – offering potential to
  personalise treatment
excerpt: Complex digital images of tissue samples that can take an experienced
  pathologist up to 20 minutes to annotate could be analysed in just one minute
  using a new AI tool developed by researchers at the University of Cambridge.
image: /assets/uploads/ai-tools-can-analyse-complex-cancer-images.jpg
date: December 8, 2025 12:00 AM
---
SMMILe, a machine learning algorithm, is able not only to correctly detect the presence of cancer cells on slides taken from biopsies and surgical sections, but it can predict where the tumour lesions are located and even the proportion of regions with different levels of aggressiveness.

The tool could be used in the future to guide a patient’s treatment, as well as helping scientists better understand how cancer develops and identify new biological signatures to improve detection.

Artificial intelligence (AI) tools offer incredible promise towards helping pathologists examine tissue samples from patients with suspected or confirmed cancer, producing ‘spatial maps’ that allow them to understand where the cancer cells are and how they are spreading. But training these tools has until now required a large number of high-quality, detailed reference slides annotated by trained pathologists.

In research published today in Nature Cancer, scientists at the University of Cambridge have developed an AI tool that can be trained using slides that have been given simple, patient-level diagnostic labels, such as cancer type or grade. Importantly, these slides did not need to include detailed region-by-region annotations from pathologists, which are time-consuming to produce.

Despite learning from such scant information, the algorithm – SMMILe (Superpatch-based Measurable Multiple Instance Learning) – was able to provide detailed information about each slide, including mapping the locations of tumour lesions, and estimating the proportions and spatial distribution of lesions with different subtypes and grades.

Dr Zeyu Gao from the Early Cancer Institute at the University of Cambridge, who developed the algorithm, said: “Cancer isn’t always uniform. A single tumour can contain different subtypes, some that are more aggressive than others. Our model doesn’t just say ‘yes, there’s cancer’, it maps out these subtypes and their proportions within the tissue. This could one day help doctors tailor treatments more effectively, moving to a more nuanced understanding of each patient’s cancer.”

The team tested the algorithm on eight datasets comprising 3,850 whole-slide images covering six cancer types: lung, kidney, ovarian, breast, stomach, and prostate cancer. When benchmarked against nine other state-of-the-art whole-slide image classification analysis AI tools, SMMILe’s performance matched – and in several cases exceeded – these tools at slide-level classification, while significantly outperforming them when it came to estimating the proportions and spatial distribution of lesions.

Dr Mireia Crispin-Ortuzar, Co-Lead of the Cancer Research UK Cambridge Centre Integrated Cancer Medicine Virtual Institute and the study’s joint senior author, said: “What we’ve developed is akin to a ‘sonar’ for images that essentially allows us to see in the dark. Often, we have information about a tumour, but we don't know how it's distributed in the tissue. There are technologies that allow you to get this information, but they are very costly.

**[Continue to read the full article here](https://www.cam.ac.uk/research/news/ai-tool-can-analyse-complex-cancer-images-rapidly-offering-potential-to-personalise-treatment)**