---
layout: person
name: Maya Indira Ganesh
title: Dr
given: "Maya "
preferred: ""
family: Indira Ganesh
job_title: Associate Director (Research Partnerships) | Programme Co-director,
  Narratives & Justice
department: Leverhulme Centre for the Future of Intelligence
biography: >-
  Maya Indira Ganesh is assistant teaching professor co-directing the MSt in AI
  Ethics & Society at the Institute for Continuing Education, and a Senior
  Researcher at LCFI at the University of Cambridge. Maya earned a Drphil in
  Cultural Studies from Leuphana University, Lueneburg, Germany. Her thesis was
  about the material, epistemic, and discursive infrastructures shaping the
  emergence of driverless cars as putatively  'ethical' and 'autonomous'. Her
  work is influenced by scholarship and practice in feminist approaches to
  technoscience, STS, Digital Anthropology, Media Studies, and Critical
  Data/Algorithm Studies. Her current research is about AI Ethics pedagogy in
  mediating the relationship between theory and practice. Between 2008-2017,
  Maya was a researcher working with digital rights organisations at the
  intersection of gender justice and digital freedom of expression with human
  rights defenders, activists, and journalists across the majority world.\

  \

  Maya Indira Ganesh is Associate Director (Research Culture & Partnerships), co-director of the [Narratives and Justice Program,](https://www.lcfi.ac.uk/research/programme/ai-narratives-and-justice) and a Senior Research Fellow at the Leverhulme Centre for the Future of Intelligence (CFI). From October 2021- July 2024 she was an assistant teaching professor at the [Institute of Continuing Education](https://www.ice.cam.ac.uk/) (ICE) where she co-directed the [MSt in AI Ethics and Society](https://www.lcfi.ac.uk/education/mst/) run jointly between ICE and CFI. Maya has masters degrees in Psychology, and in Media and Cultural Studies, and a Drphil in Cultural Studies. Her doctoral work took the case of the ‘ethics of autonomous driving’ to study the implications of ethical decision-making proposed by algorithmic/AI technologies for human social and spatial relations. Her monograph based on this work, *Auto-Correct: The Fantasies and Failures of AI, Ethics, and the Driverless Car* was published in March 2025 and can be ordered [here.](https://artezpress.artez.nl/books/auto-correct/) Maya draws on varied theoretical and methodological genres, including feminist scholarship, participatory methods, Media and Cultural studies, and Science and Technology Studies to examine how AI is being deployed in public, and how AI’s marginalised and expert publics shape the technology.


  Recent research projects include: with Louise Hickman and others, [AI in the Street](https://www.careful.industries/ai-in-the-street/overview) (2024); [Decision-making with AI in connected places and cities](https://ai.cam.ac.uk/projects/decision-making-with-ai-in-connected-places-and-cities), a collaboration with partners across the university supported by the AI@Cam initiative (2024-2026) and the UK government’s [AI Security Institute](https://www.aisi.gov.uk/work/strengthening-ai-resilience) (2025-2026); and [Ai for Cultural Heritage (ArCH),](https://ai.cam.ac.uk/projects/ai-for-cultural-heritage-hub-arch) (2025-2026), a collaboration being led by the University Library to ‘create a secure workspace and Community of Practice to empower non-technical users (practitioners and academics) to analyse cultural heritage data securely with AI tools.’ She is also an invited speaker, curatorial advisor, and essayist writing about cultural conditions of embodied life under automation and AI. Prior to academia, Maya spent over a decade as a researcher and info-activist working at the intersection of gender justice, security, and digital freedom of expression.  An up-to-date list of her publications, talks, and writing about AI/digital culture can be found [here](https://bodyofwork.in/).
image: /assets/uploads/Ganesh_Indira.jpg
webpage: http://lcfi.ac.uk/people/maya-indira-ganesh/
crsid: mi373
---
